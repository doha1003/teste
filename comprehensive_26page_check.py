#!/usr/bin/env python3
"""
26ê°œ ì£¼ìš” í˜ì´ì§€ ì™„ë²½ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸
CSS, ë ˆì´ì•„ì›ƒ, ì¤‘ë³µ ì •ì˜, ê¸°ëŠ¥ ë“± ëª¨ë“  ê²ƒì„ ì²´í¬
"""

import os
import re
import json
from collections import defaultdict

# 26ê°œ ì£¼ìš” í˜ì´ì§€ ëª©ë¡
MAIN_PAGES = [
    "index.html",
    "404.html",
    "about/index.html",
    "contact/index.html",
    "privacy/index.html",
    "terms/index.html",
    "faq/index.html",
    # ì‹¬ë¦¬í…ŒìŠ¤íŠ¸
    "tests/index.html",
    "tests/mbti/index.html",
    "tests/mbti/test.html",
    "tests/teto-egen/index.html", 
    "tests/teto-egen/start.html",
    "tests/teto-egen/test.html",
    "tests/love-dna/index.html",
    "tests/love-dna/test.html",
    # ì‹¤ìš©ë„êµ¬
    "tools/index.html",
    "tools/text-counter.html",
    "tools/bmi-calculator.html",
    "tools/salary-calculator.html",
    # AI ìš´ì„¸
    "fortune/index.html",
    "fortune/daily/index.html",
    "fortune/saju/index.html",
    "fortune/tarot/index.html",
    "fortune/zodiac/index.html",
    "fortune/zodiac-animal/index.html"
]

def check_page_issues(file_path):
    """í˜ì´ì§€ì˜ ëª¨ë“  ë¬¸ì œì  ì²´í¬"""
    issues = {
        'css_issues': [],
        'js_issues': [],
        'duplicate_definitions': [],
        'layout_issues': [],
        'missing_features': [],
        'console_errors': [],
        'accessibility': [],
        'seo_issues': []
    }
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # 1. CSS ë¬¸ì œ ì²´í¬
        # ì¸ë¼ì¸ ìŠ¤íƒ€ì¼ ì²´í¬
        inline_styles = len(re.findall(r'style=["\'](.*?)["\']', content))
        if inline_styles > 5:
            issues['css_issues'].append(f"ê³¼ë„í•œ ì¸ë¼ì¸ ìŠ¤íƒ€ì¼ ì‚¬ìš©: {inline_styles}ê°œ")
        
        # CSS íŒŒì¼ ë¡œë“œ í™•ì¸
        css_files = re.findall(r'<link[^>]*href=["\'](.*?\.css.*?)["\']', content)
        if not any('styles.css' in css for css in css_files):
            issues['css_issues'].append("ë©”ì¸ styles.cssê°€ ë¡œë“œë˜ì§€ ì•ŠìŒ")
        
        # ì¤‘ë³µ CSS íŒŒì¼ ì²´í¬
        css_counts = defaultdict(int)
        for css in css_files:
            base_css = css.split('?')[0]
            css_counts[base_css] += 1
        for css, count in css_counts.items():
            if count > 1:
                issues['duplicate_definitions'].append(f"CSS ì¤‘ë³µ ë¡œë“œ: {css} ({count}íšŒ)")
        
        # 2. JavaScript ë¬¸ì œ ì²´í¬
        # ì¤‘ë³µ ìŠ¤í¬ë¦½íŠ¸ ì²´í¬
        script_files = re.findall(r'<script[^>]*src=["\'](.*?)["\']', content)
        script_counts = defaultdict(int)
        for script in script_files:
            base_script = script.split('?')[0]
            script_counts[base_script] += 1
        for script, count in script_counts.items():
            if count > 1:
                issues['duplicate_definitions'].append(f"JS ì¤‘ë³µ ë¡œë“œ: {script} ({count}íšŒ)")
        
        # í•„ìˆ˜ ìŠ¤í¬ë¦½íŠ¸ ì²´í¬
        if 'navbar-placeholder' in content or 'footer-placeholder' in content:
            if not any('main.js' in s for s in script_files):
                issues['js_issues'].append("main.js ëˆ„ë½ - ë„¤ë¹„ê²Œì´ì…˜/í‘¸í„° ë¡œë“œ ë¶ˆê°€")
            if not any('api-config.js' in s for s in script_files):
                issues['js_issues'].append("api-config.js ëˆ„ë½ - API ê¸°ëŠ¥ ë¶ˆê°€")
        
        # 3. ë ˆì´ì•„ì›ƒ ë¬¸ì œ ì²´í¬
        # viewport ë©”íƒ€íƒœê·¸
        if not re.search(r'<meta[^>]*name=["\']*viewport["\']*', content):
            issues['layout_issues'].append("viewport ë©”íƒ€íƒœê·¸ ëˆ„ë½ - ëª¨ë°”ì¼ ë°˜ì‘í˜• ë¬¸ì œ")
        
        # ì»¨í…Œì´ë„ˆ êµ¬ì¡°
        if '<div class="container">' not in content and '<section' not in content:
            issues['layout_issues'].append("ì ì ˆí•œ ì»¨í…Œì´ë„ˆ êµ¬ì¡° ì—†ìŒ")
        
        # 4. ê¸°ëŠ¥ ì²´í¬
        # ë„¤ë¹„ê²Œì´ì…˜/í‘¸í„°
        if 'navbar-placeholder' in content and 'loadComponents' not in content:
            issues['missing_features'].append("ë„¤ë¹„ê²Œì´ì…˜ ë¡œë“œ í•¨ìˆ˜ ëˆ„ë½")
        
        # ì¹´ì¹´ì˜¤ ê³µìœ 
        if any(btn in content for btn in ['shareKakao', 'share-kakao', 'ì¹´ì¹´ì˜¤í†¡']):
            if not any('kakao' in s.lower() for s in script_files):
                issues['missing_features'].append("ì¹´ì¹´ì˜¤ SDK ëˆ„ë½ - ê³µìœ  ê¸°ëŠ¥ ë¶ˆê°€")
        
        # 5. SEO ì²´í¬
        if not re.search(r'<title>', content):
            issues['seo_issues'].append("title íƒœê·¸ ëˆ„ë½")
        if not re.search(r'<meta[^>]*name=["\']*description["\']*', content):
            issues['seo_issues'].append("description ë©”íƒ€íƒœê·¸ ëˆ„ë½")
        
        # 6. ì ‘ê·¼ì„± ì²´í¬
        # ì´ë¯¸ì§€ alt í…ìŠ¤íŠ¸
        imgs_without_alt = len(re.findall(r'<img(?![^>]*alt=)[^>]*>', content))
        if imgs_without_alt > 0:
            issues['accessibility'].append(f"alt í…ìŠ¤íŠ¸ ì—†ëŠ” ì´ë¯¸ì§€: {imgs_without_alt}ê°œ")
        
        # í¼ ë¼ë²¨
        if '<input' in content:
            inputs = len(re.findall(r'<input[^>]*>', content))
            labels = len(re.findall(r'<label', content))
            if inputs > labels:
                issues['accessibility'].append(f"ë¼ë²¨ ì—†ëŠ” ì…ë ¥ í•„ë“œ ê°€ëŠ¥ì„±: {inputs - labels}ê°œ")
        
    except Exception as e:
        issues['console_errors'].append(f"íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {str(e)}")
    
    return issues

def generate_detailed_report():
    """26ê°œ í˜ì´ì§€ ìƒì„¸ ê²€ì¦ ë¦¬í¬íŠ¸"""
    print("=" * 80)
    print("ğŸ” doha.kr 26ê°œ ì£¼ìš” í˜ì´ì§€ ì™„ë²½ ê²€ì¦ ë¦¬í¬íŠ¸")
    print("=" * 80)
    
    all_results = {}
    total_issues = 0
    perfect_pages = []
    problematic_pages = []
    
    for page in MAIN_PAGES:
        if os.path.exists(page):
            issues = check_page_issues(page)
            all_results[page] = issues
            
            # ë¬¸ì œ ê°œìˆ˜ ê³„ì‚°
            page_issue_count = sum(len(v) for v in issues.values())
            total_issues += page_issue_count
            
            if page_issue_count == 0:
                perfect_pages.append(page)
            else:
                problematic_pages.append((page, page_issue_count))
            
            # í˜ì´ì§€ë³„ ê²°ê³¼ ì¶œë ¥
            if page_issue_count > 0:
                print(f"\nâŒ {page} - {page_issue_count}ê°œ ë¬¸ì œ")
                for category, items in issues.items():
                    if items:
                        print(f"  [{category}]")
                        for item in items[:3]:  # ì²˜ìŒ 3ê°œë§Œ í‘œì‹œ
                            print(f"    â€¢ {item}")
        else:
            print(f"\nâš ï¸  {page} - íŒŒì¼ ì—†ìŒ")
    
    # ìš”ì•½
    print("\n" + "=" * 80)
    print("ğŸ“Š ê²€ì¦ ê²°ê³¼ ìš”ì•½")
    print("=" * 80)
    print(f"âœ… ì™„ë²½í•œ í˜ì´ì§€: {len(perfect_pages)}ê°œ")
    print(f"âŒ ë¬¸ì œ ìˆëŠ” í˜ì´ì§€: {len(problematic_pages)}ê°œ")
    print(f"ğŸš¨ ì´ ë¬¸ì œ ê°œìˆ˜: {total_issues}ê°œ")
    
    # ê°€ì¥ ë¬¸ì œê°€ ë§ì€ í˜ì´ì§€
    if problematic_pages:
        print("\nğŸš¨ ê°€ì¥ ë¬¸ì œê°€ ë§ì€ í˜ì´ì§€ TOP 5:")
        sorted_pages = sorted(problematic_pages, key=lambda x: x[1], reverse=True)
        for page, count in sorted_pages[:5]:
            print(f"  â€¢ {page}: {count}ê°œ ë¬¸ì œ")
    
    # ì¹´í…Œê³ ë¦¬ë³„ ë¬¸ì œ ìš”ì•½
    category_summary = defaultdict(int)
    for page_issues in all_results.values():
        for category, items in page_issues.items():
            category_summary[category] += len(items)
    
    print("\nğŸ“ˆ ì¹´í…Œê³ ë¦¬ë³„ ë¬¸ì œ ë¶„í¬:")
    for category, count in sorted(category_summary.items(), key=lambda x: x[1], reverse=True):
        if count > 0:
            print(f"  â€¢ {category}: {count}ê°œ")
    
    # JSON ì €ì¥
    with open('26page_verification_report.json', 'w', encoding='utf-8') as f:
        json.dump({
            'summary': {
                'total_pages': len(MAIN_PAGES),
                'perfect_pages': len(perfect_pages),
                'problematic_pages': len(problematic_pages),
                'total_issues': total_issues
            },
            'perfect_pages': perfect_pages,
            'problematic_pages': dict(problematic_pages),
            'detailed_results': all_results,
            'category_summary': dict(category_summary)
        }, f, ensure_ascii=False, indent=2)
    
    print("\nğŸ“ ìƒì„¸ ë¦¬í¬íŠ¸ê°€ 26page_verification_report.jsonì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    import sys
    import io
    
    if sys.platform == 'win32':
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
        sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')
    
    generate_detailed_report()